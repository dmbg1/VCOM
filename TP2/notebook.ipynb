{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic sign detection and classification (with deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path_name = './dataset/images'\n",
    "anno_path_name = './dataset/annotations'\n",
    "train_names_path = Path('./dataset/train.txt')\n",
    "test_names_path = Path('./dataset/test.txt')\n",
    "\n",
    "# Gets train or test data file names\n",
    "\n",
    "\n",
    "def train_test_file_names(train_test_data_path: Path):\n",
    "    file_names = []\n",
    "    with open(train_test_data_path, 'r') as file:\n",
    "        file_names = file.readlines()\n",
    "        file_names = [file_name.rstrip() for file_name in file_names]\n",
    "    return file_names\n",
    "\n",
    "# Generates pandas dataframe for train dataset\n",
    "\n",
    "\n",
    "def generate_train_df(train_file_names: list, only_biggest_area_object: bool):\n",
    "    anno_list = []\n",
    "    for train_file_name in train_file_names:\n",
    "        anno_xml_root = ET.parse(\n",
    "            Path(anno_path_name + \"/\" + train_file_name + \".xml\"))\n",
    "        anno = {}\n",
    "        anno['img_file_path'] = Path(\n",
    "            imgs_path_name + \"/\" + anno_xml_root.find(\"filename\").text)\n",
    "        anno['width'] = anno_xml_root.find(\"size/width\").text\n",
    "        anno['height'] = anno_xml_root.find(\"size/height\").text\n",
    "        anno['class'] = anno_xml_root.find(\"object/name\").text\n",
    "\n",
    "        xml_objects = anno_xml_root.findall(\"object\")\n",
    "        if only_biggest_area_object:\n",
    "            max_area = 0\n",
    "            max_area_obj = {}\n",
    "            for xml_object in xml_objects:\n",
    "                curr_obj = {}\n",
    "                curr_obj[\"xmin\"] = int(xml_object.find(\"bndbox/xmin\").text)\n",
    "                curr_obj[\"ymin\"] = int(xml_object.find(\"bndbox/ymin\").text)\n",
    "                curr_obj[\"xmax\"] = int(xml_object.find(\"bndbox/xmax\").text)\n",
    "                curr_obj[\"ymax\"] = int(xml_object.find(\"bndbox/ymax\").text)\n",
    "                curr_obj_area = (curr_obj[\"xmax\"] - curr_obj[\"xmin\"]) * (curr_obj[\"ymax\"] - curr_obj[\"ymin\"])\n",
    "                if curr_obj_area > max_area:\n",
    "                    max_area_obj = curr_obj\n",
    "                    max_area = curr_obj_area\n",
    "\n",
    "            anno[\"xmin\"] = max_area_obj[\"xmin\"]\n",
    "            anno[\"ymin\"] = max_area_obj[\"ymin\"]\n",
    "            anno[\"xmax\"] = max_area_obj[\"xmax\"]\n",
    "            anno[\"ymax\"] = max_area_obj[\"ymax\"]\n",
    "\n",
    "        anno_list.append(anno)\n",
    "\n",
    "    return pd.DataFrame(anno_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3721\n",
      "1666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "img_file_path    dataset/images/road327.png\n",
       "width                                   300\n",
       "height                                  400\n",
       "class                            speedlimit\n",
       "xmin                                     92\n",
       "ymin                                    173\n",
       "xmax                                    153\n",
       "ymax                                    234\n",
       "Name: 603, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(display(generate_train_df(\n",
    "    train_test_file_names(train_names_path), True).iloc[603]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_files = [name for name in os.listdir('./dataset/annotations')]\n",
    "validation_dictionary = {}\n",
    "\n",
    "for name in xml_files:\n",
    "    # Parse the xml\n",
    "    mytree = ET.parse('./dataset/annotations/' + name)\n",
    "\n",
    "    # Get number from name\n",
    "    order = ''.join(i for i in name if i.isdigit())\n",
    "\n",
    "    # Get sign types\n",
    "    validation_dictionary[order] = mytree.getroot().find(\n",
    "        'object').find('name').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trafficlight', 'speedlimit', 'stop', 'crosswalk']\n"
     ]
    }
   ],
   "source": [
    "sign_types = []\n",
    "for entry in validation_dictionary:\n",
    "    if validation_dictionary[entry] not in sign_types:\n",
    "        sign_types.append(validation_dictionary[entry])\n",
    "print(sign_types)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
