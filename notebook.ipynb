{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Traffic Signs with OpenCV\n",
    "\n",
    "For this project we will be trying split the traffic sign dataset into 3 separate classes:\n",
    "- Stop signs\n",
    "- Red Circles\n",
    "- Blue rectangles/squares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list():\n",
    "    file_list = []\n",
    "    for root, _, files in os.walk('./dataset'):\n",
    "\t    for file in files:\n",
    "\t\t    file_list.append(os.path.join(root,file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(segmented_img, original_img, color):\n",
    "    segmented_img = smooth(segmented_img)\n",
    "    if color == \"blue\":\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        segmented_img = cv.dilate(segmented_img, kernel, iterations=3)\n",
    "        segmented_img = cv.erode(segmented_img, kernel, iterations=3)\n",
    "        segmented_img = cv.Canny(segmented_img, 150, 200) \n",
    "        \n",
    "    final, prediction = search_contours(segmented_img, original_img, color)\n",
    "    \n",
    "    return final, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove image noise with gaussian blur (better at preserving edges)\n",
    "def smooth(img):\n",
    "    return cv.GaussianBlur(img, (3,3), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increases image brightness\n",
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    h, s, v = cv.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv.merge((h, s, v))\n",
    "    img = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add contrast to image by histogram equalization\n",
    "def add_contrast(img):\n",
    "    return cv.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Segments reds and blues of an image\n",
    "def segment(img, color):\n",
    "    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    if color == 'red':\n",
    "        # lower mask (0-10)\n",
    "        lower_red = np.array([0,90,50])\n",
    "        upper_red = np.array([10,255,255])\n",
    "        mask0 = cv.inRange(img_hsv, lower_red, upper_red)  \n",
    "\n",
    "        # upper mask (160-180)\n",
    "        lower_red = np.array([160,90,50])\n",
    "        upper_red = np.array([180,255,255])\n",
    "        mask1 = cv.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "        mask = mask0 | mask1\n",
    "    elif color == 'blue':\n",
    "        lower_blue = np.array([100,160,50])\n",
    "        upper_blue = np.array([130,255,255])\n",
    "        mask = cv.inRange(img_hsv, lower_blue, upper_blue) \n",
    "\n",
    "    segmented_img = cv.bitwise_and(img_hsv, img_hsv, mask = mask)\n",
    "    segmented_img = cv.cvtColor(segmented_img, cv.COLOR_BGR2GRAY)\n",
    "    return segmented_img    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contour with the largest area in a gray scale image\n",
    "def find_largest_contour(segmented_img, original_img):\n",
    "    contours, _ = cv.findContours(segmented_img,2,1)\n",
    "    cnt = contours\n",
    "    big_contour = []\n",
    "    max = 0\n",
    "    for i in cnt:\n",
    "        area = cv.contourArea(i)\n",
    "        if(area > max):\n",
    "            max = area\n",
    "            big_contour = i \n",
    "    if max > 1000 and len(big_contour) > 25 and len(big_contour) < 1200:\n",
    "        final = cv.drawContours(original_img, big_contour, -1, (0,255,0), 3)\n",
    "    else:\n",
    "        final = original_img\n",
    "\n",
    "    return final, big_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Improve sensibility to blue squares \n",
    "# Find a blue square\n",
    "def search_contours(segmented_img, original_img, color):\n",
    "    if cv.countNonZero(segmented_img) == 0:\n",
    "        return segmented_img, 'unrecognised'\n",
    "    final, contour = find_largest_contour(segmented_img, original_img)\n",
    "    if len(contour) > 100:\n",
    "        peri = cv.arcLength(contour, True)\n",
    "        approx = cv.approxPolyDP(contour, 0.01 * peri, True)\n",
    "        return final, classify_sign(approx, color)\n",
    "\n",
    "    return final, 'unrecognised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sign(approx_cnt, color):\n",
    "    if color == 'blue':\n",
    "        if len(approx_cnt) == 4:\n",
    "            return 'blue_square'\n",
    "    elif color == 'red':\n",
    "        if len(approx_cnt) == 8:\n",
    "            return 'stop_sign'\n",
    "        elif len(approx_cnt > 8):\n",
    "            return 'red_circle'\n",
    "    return 'unrecognised'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Circles\n",
    "\n",
    "This is the section to detect red circles\n",
    "\n",
    "After processing the image to gray values holding as the white value the red features a contour finder is used to detect an ellipse correctly. It can also be used in the case of stop signs to obtain octagons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./dataset/road161.png': 'blue_square', './dataset/road143.png': 'blue_square', './dataset/road246.png': 'unrecognised', './dataset/road302.png': 'unrecognised', './dataset/road132.png': 'blue_square', './dataset/road204.png': 'blue_square', './dataset/road330.png': 'unrecognised', './dataset/road215.png': 'unrecognised', './dataset/road235.png': 'unrecognised', './dataset/road118.png': 'red_circle', './dataset/road76.png': 'stop_sign', './dataset/road182.png': 'unrecognised', './dataset/road344.png': 'stop_sign', './dataset/road321.png': 'unrecognised', './dataset/road221.png': 'unrecognised', './dataset/road133.png': 'blue_square', './dataset/road157.png': 'blue_square', './dataset/road115.png': 'red_circle', './dataset/road268.png': 'unrecognised', './dataset/road212.png': 'unrecognised', './dataset/road89.png': 'red_circle', './dataset/road91.png': 'stop_sign', './dataset/road96.png': 'stop_sign', './dataset/road240.png': 'unrecognised', './dataset/road245.png': 'red_circle', './dataset/road134.png': 'blue_square', './dataset/road599.png': 'red_circle', './dataset/road117.png': 'red_circle', './dataset/road354.png': 'unrecognised', './dataset/road57.png': 'stop_sign', './dataset/road224.png': 'unrecognised', './dataset/road218.png': 'unrecognised', './dataset/road72.png': 'stop_sign', './dataset/road312.png': 'unrecognised', './dataset/road227.png': 'unrecognised', './dataset/road244.png': 'red_circle', './dataset/road323.png': 'unrecognised', './dataset/road94.png': 'stop_sign', './dataset/road177.png': 'red_circle', './dataset/road273.png': 'red_circle', './dataset/road230.png': 'unrecognised', './dataset/road249.png': 'unrecognised', './dataset/road172.png': 'unrecognised', './dataset/road136.png': 'unrecognised', './dataset/road95.png': 'red_circle', './dataset/road193.png': 'blue_square', './dataset/road174.png': 'blue_square', './dataset/road351.png': 'unrecognised', './dataset/road201.png': 'red_circle', './dataset/road194.png': 'unrecognised', './dataset/road340.png': 'red_circle', './dataset/road159.png': 'red_circle', './dataset/road175.png': 'blue_square', './dataset/road256.png': 'blue_square', './dataset/road348.png': 'red_circle', './dataset/road79.png': 'stop_sign', './dataset/road162.png': 'red_circle', './dataset/road97.png': 'stop_sign', './dataset/road237.png': 'unrecognised', './dataset/road190.png': 'blue_square', './dataset/road322.png': 'blue_square', './dataset/road80.png': 'stop_sign', './dataset/road113.png': 'red_circle', './dataset/road209.png': 'red_circle', './dataset/road232.png': 'unrecognised', './dataset/road167.png': 'stop_sign', './dataset/road337.png': 'red_circle', './dataset/road67.png': 'stop_sign', './dataset/road223.png': 'unrecognised', './dataset/road101.png': 'red_circle', './dataset/road138.png': 'blue_square', './dataset/road208.png': 'red_circle', './dataset/road109.png': 'red_circle', './dataset/road55.png': 'red_circle', './dataset/road206.png': 'blue_square', './dataset/road288.png': 'unrecognised', './dataset/road137.png': 'blue_square', './dataset/road180.png': 'blue_square', './dataset/road124.png': 'red_circle', './dataset/road71.png': 'stop_sign', './dataset/road93.png': 'stop_sign', './dataset/road119.png': 'red_circle', './dataset/road284.png': 'unrecognised', './dataset/road292.png': 'unrecognised', './dataset/road189.png': 'blue_square', './dataset/road178.png': 'blue_square', './dataset/road314.png': 'blue_square', './dataset/road74.png': 'red_circle', './dataset/road259.png': 'unrecognised', './dataset/road98.png': 'stop_sign', './dataset/road63.png': 'red_circle', './dataset/road346.png': 'unrecognised', './dataset/road100.png': 'red_circle', './dataset/road213.png': 'unrecognised', './dataset/road183.png': 'red_circle', './dataset/road203.png': 'unrecognised', './dataset/road186.png': 'unrecognised', './dataset/road236.png': 'unrecognised', './dataset/road338.png': 'red_circle', './dataset/road233.png': 'unrecognised', './dataset/road198.png': 'unrecognised', './dataset/road106.png': 'red_circle', './dataset/road165.png': 'stop_sign', './dataset/road151.png': 'blue_square', './dataset/road342.png': 'red_circle', './dataset/road197.png': 'unrecognised', './dataset/road78.png': 'stop_sign', './dataset/road333.png': 'unrecognised', './dataset/road52.png': 'stop_sign', './dataset/road331.png': 'red_circle', './dataset/road289.png': 'red_circle', './dataset/road69.png': 'stop_sign', './dataset/road270.png': 'red_circle', './dataset/road54.png': 'red_circle', './dataset/road131.png': 'unrecognised', './dataset/road320.png': 'unrecognised', './dataset/road111.png': 'red_circle', './dataset/road231.png': 'unrecognised', './dataset/road154.png': 'unrecognised', './dataset/road300.png': 'unrecognised', './dataset/road68.png': 'stop_sign', './dataset/road199.png': 'unrecognised', './dataset/road92.png': 'stop_sign', './dataset/road350.png': 'unrecognised', './dataset/road171.png': 'red_circle', './dataset/road129.png': 'unrecognised', './dataset/road303.png': 'unrecognised', './dataset/road324.png': 'blue_square', './dataset/road332.png': 'unrecognised', './dataset/road229.png': 'unrecognised', './dataset/road299.png': 'unrecognised', './dataset/road166.png': 'blue_square', './dataset/road250.png': 'unrecognised', './dataset/road88.png': 'stop_sign', './dataset/road336.png': 'unrecognised', './dataset/road317.png': 'unrecognised', './dataset/road277.png': 'unrecognised', './dataset/road597.png': 'unrecognised', './dataset/road264.png': 'red_circle', './dataset/road164.png': 'red_circle', './dataset/road155.png': 'unrecognised', './dataset/road293.png': 'red_circle', './dataset/road104.png': 'red_circle', './dataset/road176.png': 'unrecognised', './dataset/road149.png': 'unrecognised', './dataset/road126.png': 'unrecognised', './dataset/road254.png': 'blue_square', './dataset/road150.png': 'blue_square', './dataset/road282.png': 'unrecognised', './dataset/road60.png': 'stop_sign', './dataset/road357.png': 'red_circle', './dataset/road152.png': 'blue_square', './dataset/road234.png': 'unrecognised', './dataset/road66.png': 'red_circle', './dataset/road228.png': 'unrecognised', './dataset/road280.png': 'unrecognised', './dataset/road335.png': 'unrecognised', './dataset/road279.png': 'red_circle', './dataset/road65.png': 'stop_sign', './dataset/road105.png': 'red_circle', './dataset/road290.png': 'unrecognised', './dataset/road261.png': 'unrecognised', './dataset/road62.png': 'stop_sign', './dataset/road294.png': 'red_circle', './dataset/road181.png': 'unrecognised', './dataset/road142.png': 'blue_square', './dataset/road59.png': 'stop_sign', './dataset/road307.png': 'blue_square', './dataset/road205.png': 'blue_square', './dataset/road329.png': 'red_circle', './dataset/road222.png': 'unrecognised', './dataset/road217.png': 'unrecognised', './dataset/road202.png': 'red_circle', './dataset/road356.png': 'unrecognised', './dataset/road595.png': 'unrecognised', './dataset/road239.png': 'unrecognised', './dataset/road242.png': 'red_circle', './dataset/road275.png': 'red_circle', './dataset/road313.png': 'blue_square', './dataset/road168.png': 'blue_square', './dataset/road347.png': 'unrecognised', './dataset/road311.png': 'blue_square', './dataset/road319.png': 'red_circle', './dataset/road269.png': 'unrecognised', './dataset/road260.png': 'blue_square', './dataset/road153.png': 'blue_square', './dataset/road53.png': 'stop_sign', './dataset/road295.png': 'unrecognised', './dataset/road184.png': 'red_circle', './dataset/road287.png': 'blue_square', './dataset/road75.png': 'stop_sign', './dataset/road355.png': 'red_circle', './dataset/road253.png': 'unrecognised', './dataset/road58.png': 'stop_sign', './dataset/road102.png': 'red_circle', './dataset/road283.png': 'red_circle', './dataset/road207.png': 'unrecognised', './dataset/road328.png': 'blue_square', './dataset/road173.png': 'red_circle', './dataset/road99.png': 'stop_sign', './dataset/road120.png': 'red_circle', './dataset/road220.png': 'unrecognised', './dataset/road247.png': 'unrecognised', './dataset/road188.png': 'red_circle', './dataset/road265.png': 'red_circle', './dataset/road285.png': 'unrecognised', './dataset/road291.png': 'unrecognised', './dataset/road179.png': 'red_circle', './dataset/road110.png': 'red_circle', './dataset/road128.png': 'unrecognised', './dataset/road278.png': 'red_circle', './dataset/road339.png': 'red_circle', './dataset/road122.png': 'unrecognised', './dataset/road298.png': 'unrecognised', './dataset/road123.png': 'blue_square', './dataset/road121.png': 'red_circle', './dataset/road116.png': 'red_circle', './dataset/road146.png': 'blue_square', './dataset/road85.png': 'red_circle', './dataset/road226.png': 'unrecognised', './dataset/road86.png': 'red_circle', './dataset/road219.png': 'unrecognised', './dataset/road141.png': 'red_circle', './dataset/road257.png': 'unrecognised', './dataset/road325.png': 'red_circle', './dataset/road309.png': 'blue_square', './dataset/road107.png': 'red_circle', './dataset/road61.png': 'stop_sign', './dataset/road596.png': 'unrecognised', './dataset/road130.png': 'red_circle', './dataset/road334.png': 'unrecognised', './dataset/road241.png': 'unrecognised', './dataset/road163.png': 'red_circle', './dataset/road248.png': 'red_circle', './dataset/road598.png': 'unrecognised', './dataset/road156.png': 'unrecognised', './dataset/road341.png': 'unrecognised', './dataset/road125.png': 'blue_square', './dataset/road84.png': 'blue_square', './dataset/road192.png': 'red_circle', './dataset/road326.png': 'unrecognised', './dataset/road90.png': 'red_circle', './dataset/road187.png': 'red_circle', './dataset/road216.png': 'unrecognised', './dataset/road349.png': 'red_circle', './dataset/road211.png': 'unrecognised', './dataset/road262.png': 'unrecognised', './dataset/road353.png': 'blue_square', './dataset/road64.png': 'stop_sign', './dataset/road103.png': 'red_circle', './dataset/road225.png': 'unrecognised', './dataset/road70.png': 'stop_sign', './dataset/road77.png': 'stop_sign', './dataset/road266.png': 'unrecognised', './dataset/road214.png': 'unrecognised', './dataset/road345.png': 'red_circle', './dataset/road306.png': 'red_circle', './dataset/road81.png': 'stop_sign', './dataset/road114.png': 'red_circle', './dataset/road305.png': 'unrecognised', './dataset/road210.png': 'unrecognised', './dataset/road296.png': 'red_circle', './dataset/road297.png': 'red_circle', './dataset/road158.png': 'blue_square', './dataset/road139.png': 'unrecognised', './dataset/road144.png': 'blue_square', './dataset/road56.png': 'red_circle', './dataset/road308.png': 'unrecognised', './dataset/road196.png': 'red_circle', './dataset/road272.png': 'red_circle', './dataset/road135.png': 'red_circle', './dataset/road87.png': 'stop_sign', './dataset/road310.png': 'red_circle', './dataset/road255.png': 'unrecognised', './dataset/road148.png': 'unrecognised', './dataset/road82.png': 'red_circle', './dataset/road258.png': 'unrecognised', './dataset/road200.png': 'unrecognised', './dataset/road276.png': 'unrecognised', './dataset/road243.png': 'unrecognised', './dataset/road73.png': 'red_circle', './dataset/road147.png': 'unrecognised', './dataset/road281.png': 'unrecognised', './dataset/road238.png': 'unrecognised', './dataset/road127.png': 'blue_square', './dataset/road145.png': 'unrecognised', './dataset/road263.png': 'red_circle', './dataset/road352.png': 'unrecognised', './dataset/road327.png': 'red_circle', './dataset/road160.png': 'stop_sign', './dataset/road191.png': 'unrecognised', './dataset/road301.png': 'unrecognised', './dataset/road140.png': 'red_circle', './dataset/road304.png': 'unrecognised', './dataset/road170.png': 'blue_square', './dataset/road267.png': 'unrecognised', './dataset/road343.png': 'unrecognised', './dataset/road316.png': 'blue_square', './dataset/road83.png': 'stop_sign', './dataset/road185.png': 'red_circle', './dataset/road112.png': 'red_circle', './dataset/road315.png': 'unrecognised', './dataset/road252.png': 'unrecognised', './dataset/road286.png': 'red_circle', './dataset/road251.png': 'unrecognised', './dataset/road318.png': 'blue_square', './dataset/road169.png': 'red_circle', './dataset/road271.png': 'red_circle', './dataset/road274.png': 'red_circle'}\n"
     ]
    }
   ],
   "source": [
    "prediction = {}\n",
    "shutil.rmtree('results/blue_squares')\n",
    "shutil.rmtree('results/red_circles')\n",
    "shutil.rmtree('results/stop_signs')\n",
    "shutil.rmtree('results/unrecogniseds')\n",
    "os.mkdir('results/blue_squares')\n",
    "os.mkdir('results/red_circles')\n",
    "os.mkdir('results/stop_signs')\n",
    "os.mkdir('results/unrecogniseds')\n",
    "for file in get_file_list():\n",
    "    img = cv.imread(file)\n",
    "    original = img.copy()\n",
    "    img = smooth(img)\n",
    "    img = increase_brightness(img)\n",
    "    # cv.imshow(\"original\", img)\n",
    "    img_blue, img_red = segment(img, 'blue'), segment(img, 'red')\n",
    "    \n",
    "    # cv.imshow(\"filtered blue\", img_blue)\n",
    "    # cv.imshow(\"filtered red\", img_red)\n",
    "    \n",
    "    final, prediction[file] = process_image(img_blue, img.copy(), 'blue')\n",
    "    if prediction[file] == 'unrecognised':\n",
    "        final, prediction[file] = process_image(img_red, img.copy(), 'red')\n",
    "\n",
    "    if prediction[file] == 'unrecognised':\n",
    "        final = original\n",
    "        \n",
    "    cv.imwrite('./results/' + prediction[file]+'s'+'/'+ file.split('/')[-1], final)\n",
    "    # cv.imshow(prediction[file], final)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "print(prediction)\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a perfect circle\n",
    "\n",
    "By using the HoughCircles function we are able to detect perfect circles in an image.\n",
    "\n",
    "There are some cases where it fits very well but if the sign is slanted no decent circle can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray_blurred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58621/4223733673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcircles\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_blurred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOUGH_GRADIENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ensure at least some circles were found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcircles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gray_blurred' is not defined"
     ]
    }
   ],
   "source": [
    "circles =  cv.HoughCircles(gray_blurred, cv.HOUGH_GRADIENT, 1.5, 100)\n",
    "output = img.copy()\n",
    "# ensure at least some circles were found\n",
    "print(circles)\n",
    "if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "    # loop over the (x, y) coordinates and radius of the circles\n",
    "    for (x, y, r) in circles:\n",
    "        # draw the circle in the output image, then draw a rectangle\n",
    "        # corresponding to the center of the circle\n",
    "        cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "        cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1) #center of circle\n",
    "        # show the output image\n",
    "    # cv.imshow(\"output\", np.hstack([img, output]))\n",
    "\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commented out cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we need to collect all of the xml files and the corresponding png files so we can parse them.\n",
    "Our dataset has 877 pictures of traffic sings with 4 distinctions: 'trafficlight', 'speedlimit', 'crosswalk' and 'stop'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml_files = [name for name in os.listdir('./Dataset/annotations')]\n",
    "# validation_dictionary = {}\n",
    "\n",
    "# for name in xml_files:\n",
    "#     # Parse the xml\n",
    "#     mytree = ET.parse('./Dataset/annotations/' + name)\n",
    "    \n",
    "#     # Get number from name\n",
    "#     order = ''.join(i for i in name if i.isdigit())\n",
    "    \n",
    "#     # Get sign type\n",
    "#     validation_dictionary[order] = mytree.getroot().find('object').find('name').text\n",
    "\n",
    "# sign_types = []\n",
    "# for entry in validation_dictionary:\n",
    "#     if validation_dictionary[entry] not in sign_types:\n",
    "#         sign_types.append(validation_dictionary[entry])\n",
    "# print(sign_types)\n",
    "# print(validation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
