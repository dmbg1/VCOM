{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Traffic Signs with OpenCV\n",
    "\n",
    "For this project we will be trying split the traffic sign dataset into 3 separate classes:\n",
    "- Stop signs\n",
    "- Red Circles\n",
    "- Blue rectangles/squares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list():\n",
    "    file_list = []\n",
    "    for root, _, files in os.walk('./Dataset'):\n",
    "\t    for file in files:\n",
    "\t\t    file_list.append(os.path.join(root,file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img, color):\n",
    "    img = smooth(img)\n",
    "    if color == \"blue\":\n",
    "        kernel = np.ones((7,7), np.uint8)\n",
    "        img = cv.dilate(img, kernel, iterations=3)\n",
    "        img = cv.erode(img, kernel, iterations=3)\n",
    "    img = cv.Canny(img, 100, 200) \n",
    "    final, prediction = search_contours(img, color)\n",
    "    \n",
    "    return final, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove image noise with gaussian blur (better at preserving edges)\n",
    "def smooth(img):\n",
    "    return cv.GaussianBlur(img, (3,3), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1999291752.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_41402/1999291752.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def increase_brightness(img, value = 30):\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Increases image brightness\n",
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    h, s, v = cv.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv.merge((h, s, v))\n",
    "    img = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add contrast to image by histogram equalization\n",
    "def add_contrast(img):\n",
    "    return cv.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Segments reds and blues of an image\n",
    "def segment(img, color):\n",
    "    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    if color == 'red':\n",
    "        # lower mask (0-10)\n",
    "        lower_red = np.array([0,90,50])\n",
    "        upper_red = np.array([10,255,255])\n",
    "        mask0 = cv.inRange(img_hsv, lower_red, upper_red)  \n",
    "\n",
    "        # upper mask (170-180)\n",
    "        lower_red = np.array([170,90,50])\n",
    "        upper_red = np.array([180,255,255])\n",
    "        mask1 = cv.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "        mask = mask0 | mask1\n",
    "    elif color == 'blue':\n",
    "        lower_blue = np.array([100,160,80])\n",
    "        upper_blue = np.array([130,255,170])\n",
    "        mask = cv.inRange(img_hsv, lower_blue, upper_blue) \n",
    "\n",
    "    segmented_img = cv.bitwise_and(img_hsv, img_hsv, mask = mask)\n",
    "    segmented_img = cv.cvtColor(segmented_img, cv.COLOR_BGR2GRAY)\n",
    "    return segmented_img    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contour with the largest area in a gray scale image\n",
    "def find_largest_contour(img_blurred):\n",
    "    contours, _ = cv.findContours(img_blurred,2,1)\n",
    "    cnt = contours\n",
    "    big_contour = []\n",
    "    max = 0\n",
    "    for i in cnt:\n",
    "        area = cv.contourArea(i)\n",
    "        if(area > max):\n",
    "            max = area\n",
    "            big_contour = i \n",
    "    if max > 1000 and len(big_contour) > 25 and len(big_contour) < 1200:\n",
    "        final = cv.drawContours(img, big_contour, -1, (0,255,0), 3)\n",
    "    else:\n",
    "        final = img\n",
    "\n",
    "    print(cv.arcLength(big_contour, True))\n",
    "    return final, big_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Improve sensibility to blue squares \n",
    "# Find a blue square\n",
    "def search_contours(img, color):\n",
    "    if cv.countNonZero(img) == 0:\n",
    "        return img, 'unrecognised'\n",
    "    final, contour = find_largest_contour(img)\n",
    "    if len(contour > 100):\n",
    "        peri = cv.arcLength(contour, True)\n",
    "        approx = cv.approxPolyDP(contour, 0.01 * peri, True)\n",
    "        if color == 'blue':\n",
    "            if len(approx) == 4:\n",
    "                return final, 'square'\n",
    "        elif color == 'red':\n",
    "                # Find type of red sign\n",
    "                if len(approx) == 8 :\n",
    "                    return final, 'stop_sign'\n",
    "                elif len(approx) > 8:\n",
    "                    return final, 'red_circle'\n",
    "\n",
    "    return final, 'unrecognised'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Circles\n",
    "\n",
    "This is the section to detect red circles\n",
    "\n",
    "After processing the image to gray values holding as the white value the red features a contour finder is used to detect an ellipse correctly. It can also be used in the case of stop signs to obtain octagons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qt: Session management error: Could not open network socket\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.1959581375122\n",
      "423.79898953437805\n",
      "96.66904675960541\n",
      "391.2132030725479\n",
      "43.65685415267944\n",
      "77.94112491607666\n",
      "80.5269113779068\n",
      "657.0264731645584\n",
      "26.14213538169861\n",
      "436.1320307254791\n",
      "46.485281229019165\n",
      "140.28427076339722\n",
      "184.2670258283615\n",
      "148.1421353816986\n",
      "15.41421353816986\n",
      "33.65685415267944\n",
      "15.656854152679443\n",
      "42.24264061450958\n",
      "274.16652059555054\n",
      "173.25483322143555\n",
      "142.72792184352875\n",
      "550.0142805576324\n",
      "12.242640614509583\n",
      "51.899494767189026\n",
      "98.48528122901917\n",
      "17.41421353816986\n",
      "27.071067690849304\n",
      "332.97770273685455\n",
      "10.0\n",
      "47.69848430156708\n",
      "390.97770273685455\n",
      "27.41421353816986\n",
      "22.82842707633972\n",
      "127.9827550649643\n",
      "10.828427076339722\n",
      "786.5239470005035\n",
      "106.62741661071777\n",
      "58.38477599620819\n",
      "113.94112491607666\n",
      "1032.6416971683502\n",
      "144.18376553058624\n",
      "11.41421353816986\n",
      "96.91168737411499\n"
     ]
    }
   ],
   "source": [
    "prediction = {}\n",
    "for file in get_file_list():\n",
    "    img = cv.imread(file)\n",
    "    img = smooth(img)\n",
    "    img = increase_brightness(img)\n",
    "    \n",
    "    img_blue, img_red = segment(img, 'blue'), segment(img, 'red')\n",
    "    \n",
    "    cv.imshow(\"filtered blue\", img_blue)\n",
    "    cv.imshow(\"filtered red\", img_red)\n",
    "    \n",
    "    final, prediction[file] = process_image(img_blue, 'blue')\n",
    "    if prediction[file] == 'unrecognised':\n",
    "        final, prediction[file] = process_image(img_red, 'red')\n",
    "        \n",
    "    cv.imshow(prediction[file], final)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "print(prediction)\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a perfect circle\n",
    "\n",
    "By using the HoughCircles function we are able to detect perfect circles in an image.\n",
    "\n",
    "There are some cases where it fits very well but if the sign is slanted no decent circle can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray_blurred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26389/403045815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcircles\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_blurred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOUGH_GRADIENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ensure at least some circles were found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcircles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gray_blurred' is not defined"
     ]
    }
   ],
   "source": [
    "circles =  cv.HoughCircles(gray_blurred, cv.HOUGH_GRADIENT, 1.5, 100)\n",
    "output = img.copy()\n",
    "# ensure at least some circles were found\n",
    "print(circles)\n",
    "if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "    # loop over the (x, y) coordinates and radius of the circles\n",
    "    for (x, y, r) in circles:\n",
    "        # draw the circle in the output image, then draw a rectangle\n",
    "        # corresponding to the center of the circle\n",
    "        cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "        cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1) #center of circle\n",
    "        # show the output image\n",
    "    cv.imshow(\"output\", np.hstack([img, output]))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commented out cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we need to collect all of the xml files and the corresponding png files so we can parse them.\n",
    "Our dataset has 877 pictures of traffic sings with 4 distinctions: 'trafficlight', 'speedlimit', 'crosswalk' and 'stop'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml_files = [name for name in os.listdir('./Dataset/annotations')]\n",
    "# validation_dictionary = {}\n",
    "\n",
    "# for name in xml_files:\n",
    "#     # Parse the xml\n",
    "#     mytree = ET.parse('./Dataset/annotations/' + name)\n",
    "    \n",
    "#     # Get number from name\n",
    "#     order = ''.join(i for i in name if i.isdigit())\n",
    "    \n",
    "#     # Get sign type\n",
    "#     validation_dictionary[order] = mytree.getroot().find('object').find('name').text\n",
    "\n",
    "# sign_types = []\n",
    "# for entry in validation_dictionary:\n",
    "#     if validation_dictionary[entry] not in sign_types:\n",
    "#         sign_types.append(validation_dictionary[entry])\n",
    "# print(sign_types)\n",
    "# print(validation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
