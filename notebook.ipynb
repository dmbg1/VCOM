{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Traffic Signs with OpenCV\n",
    "\n",
    "For this project we will be trying split the traffic sign dataset into 3 separate classes:\n",
    "- Stop signs\n",
    "- Red Circles\n",
    "- Blue rectangles/squares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import xml.etree.ElementTree as ET\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image color model to hsv\n",
    "def cvt_color_to_hsv(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# Remove image noise with gaussian blur (better at preserving edges)\n",
    "def remove_noise(img):\n",
    "    img = cv.GaussianBlur(img, 3)\n",
    "\n",
    "# Add contrast to image by histogram equalization\n",
    "def add_contrast(img):\n",
    "    img = cv.equalizeHist(img)\n",
    "\n",
    "# Filter reds in image using a mask by converting colors different than red black\n",
    "def filter_red(img):\n",
    "    # lower mask (0-10)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    lower_red = np.array([0,70,50])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    mask0 = cv.inRange(img, lower_red, upper_red)  \n",
    "\n",
    "    # upper mask (170-180)\n",
    "    lower_red = np.array([170,70,50])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask1 = cv.inRange(img, lower_red, upper_red)\n",
    "\n",
    "    mask = mask0 | mask1\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Filter blues in image using a mask by converting colors different than blue black\n",
    "def filter_blue(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([100,90,80])\n",
    "    upper_blue = np.array([130,255,170])\n",
    "    mask = cv.inRange(img, lower_blue, upper_blue)  \n",
    "\n",
    "    return mask\n",
    "\n",
    "# Find the contour with the largest area in a gray scale image\n",
    "def find_largest_contour(img_blurred):\n",
    "    contours,hierarchy = cv.findContours(img_blurred,2,1)\n",
    "    cnt = contours\n",
    "    big_contour = []\n",
    "    max = 0\n",
    "    for i in cnt:\n",
    "        area = cv.contourArea(i)\n",
    "        if(area > max):\n",
    "            max = area\n",
    "            big_contour = i \n",
    "\n",
    "    final = cv.drawContours(img, big_contour, -1, (0,255,0), 3)\n",
    "    return final, big_contour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blue squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_data_dir='./Dataset/blue_squares'\n",
    "img = cv.imread(os.path.join(blue_data_dir,'road123.png'))\n",
    "#billateral filtering\n",
    "imgWithMeanFilter = cv.bilateralFilter(img, 15, 75, 75)\n",
    "\n",
    "#histogram equalization\n",
    "R, G, B = cv.split(imgWithMeanFilter)\n",
    "output1_R = cv.equalizeHist(R)\n",
    "output1_G = cv.equalizeHist(G)\n",
    "output1_B = cv.equalizeHist(B)\n",
    "equ = cv.merge((output1_R, output1_G, output1_B))\n",
    "\n",
    "\n",
    "\n",
    "cv.imshow(\"original\", img)\n",
    "cv.imshow(\"filtered\", equ)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_data_dir = './Dataset/stop_signs'\n",
    "img = cv.imread(os.path.join(stop_data_dir, 'road62.png'))\n",
    "cv.imshow(\"original\", img)\n",
    "img2 = filter_red(img)\n",
    "cv.imshow(\"filtered\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./Dataset\\\\blue_squares\\\\road123.png': 'square', './Dataset\\\\blue_squares\\\\road125.png': 'red_circle', './Dataset\\\\blue_squares\\\\road127.png': 'red_circle', './Dataset\\\\blue_squares\\\\road143.png': 'square', './Dataset\\\\blue_squares\\\\road193.png': 'red_circle', './Dataset\\\\blue_squares\\\\road204.png': 'stop_sign', './Dataset\\\\red_circles\\\\road100.png': 'red_circle', './Dataset\\\\red_circles\\\\road102.png': 'red_circle', './Dataset\\\\red_circles\\\\road104.png': 'red_circle', './Dataset\\\\red_circles\\\\road105.png': 'red_circle', './Dataset\\\\red_circles\\\\road106.png': 'red_circle', './Dataset\\\\red_circles\\\\road111.png': 'red_circle', './Dataset\\\\stop_signs\\\\road52.png': 'stop_sign', './Dataset\\\\stop_signs\\\\road57.png': 'stop_sign', './Dataset\\\\stop_signs\\\\road58.png': 'stop_sign', './Dataset\\\\stop_signs\\\\road59.png': 'stop_sign', './Dataset\\\\stop_signs\\\\road60.png': 'stop_sign', './Dataset\\\\stop_signs\\\\road62.png': 'stop_sign'}\n"
     ]
    }
   ],
   "source": [
    "filelist = []\n",
    "for root, dirs, files in os.walk('./Dataset'):\n",
    "\tfor file in files:\n",
    "\t\tfilelist.append(os.path.join(root,file))\n",
    "  \n",
    "prediction = {}\n",
    "for file in filelist:\n",
    "    approx = []\n",
    "    img = cv.imread(file)\n",
    "    gray_red_blurred = cv.blur(filter_red(img), (3, 3))\n",
    "    gray_blue_blurred = cv.blur(filter_blue(img), (3, 3))\n",
    "    \n",
    "    cv.imshow(\"filtered and blurred red\", gray_red_blurred)\n",
    "    cv.imshow(\"filtered and blurred blue\", gray_blue_blurred)\n",
    "        \n",
    "    if cv.countNonZero(gray_blue_blurred) != 0:\n",
    "        final, contour = find_largest_contour(gray_blue_blurred)\n",
    "    \n",
    "    if cv.countNonZero(gray_red_blurred) != 0:\n",
    "        final, contour = find_largest_contour(gray_red_blurred)\n",
    "    \n",
    "    if len(contour) != 0:\n",
    "        peri = cv.arcLength(contour, True)\n",
    "        approx = cv.approxPolyDP(contour, 0.01 * peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        prediction[file] = 'square'\n",
    "    elif len(approx) == 8:\n",
    "        prediction[file] = 'stop_sign'\n",
    "    elif len(approx) >= 9:\n",
    "        prediction[file] = 'red_circle'\n",
    "    else:\n",
    "        prediction[file] = 'unrecognised'\n",
    "    \n",
    "    \n",
    "    cv.imshow('final', final)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "print(prediction)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has 877 pictures of traffic sings with 4 distinctions: 'trafficlight', 'speedlimit', 'crosswalk' and 'stop'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Circles\n",
    "\n",
    "This is the section to detect red circles\n",
    "\n",
    "After processing the image to gray values holding as the white value the red features a contour finder is used to detect an ellipse correctly. It can also be used in the case of stop signs to obtain hexagons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[106  41]]\n",
      "\n",
      " [[105  42]]\n",
      "\n",
      " [[104  43]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[109  41]]\n",
      "\n",
      " [[108  41]]\n",
      "\n",
      " [[107  41]]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "red_circle_data_dir = './Dataset/stop_signs'\n",
    "img = cv.imread(os.path.join(red_circle_data_dir, 'road57.png'))\n",
    "cv.imshow(\"original\", img)\n",
    "gray_blurred = cv.blur(filter_red(img), (3, 3))\n",
    "cv.imshow(\"filtered and blurred\", gray_blurred)\n",
    "\n",
    "final, contour = find_largest_contour(gray_blurred)\n",
    "\n",
    "peri = cv.arcLength(contour, True)\n",
    "\n",
    "approx = cv.approxPolyDP(contour, 0.01 * peri, True)\n",
    "\n",
    "print(len(approx))\n",
    "\n",
    "# if len = 8 it is a stop sign ?\n",
    "# else if len > 10 it is a red circle\n",
    "\n",
    "cv.imshow('final', final)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a perfect circle\n",
    "\n",
    "By using the HoughCircles function we are able to detect perfect circles in an image.\n",
    "\n",
    "There are some cases where it fits very well but if the sign is slanted no decent circle can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[216.75    183.75    172.20001]]]\n"
     ]
    }
   ],
   "source": [
    "circles =  cv.HoughCircles(gray_blurred, cv.HOUGH_GRADIENT, 1.5, 100)\n",
    "output = img.copy()\n",
    "# ensure at least some circles were found\n",
    "print(circles)\n",
    "if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "    # loop over the (x, y) coordinates and radius of the circles\n",
    "    for (x, y, r) in circles:\n",
    "        # draw the circle in the output image, then draw a rectangle\n",
    "        # corresponding to the center of the circle\n",
    "        cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "        cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1) #center of circle\n",
    "        # show the output image\n",
    "    cv.imshow(\"output\", np.hstack([img, output]))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commented out cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we need to collect all of the xml files and the corresponding png files so we can parse them.\n",
    "Our dataset has 877 pictures of traffic sings with 4 distinctions: 'trafficlight', 'speedlimit', 'crosswalk' and 'stop'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\FEUP\\VC\\Project1\\VCOM\\notebook.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FEUP/VC/Project1/VCOM/notebook.ipynb#ch0000008?line=0'>1</a>\u001b[0m sign_types \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FEUP/VC/Project1/VCOM/notebook.ipynb#ch0000008?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m validation_dictionary:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FEUP/VC/Project1/VCOM/notebook.ipynb#ch0000008?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m validation_dictionary[entry] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sign_types:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FEUP/VC/Project1/VCOM/notebook.ipynb#ch0000008?line=3'>4</a>\u001b[0m         sign_types\u001b[39m.\u001b[39mappend(validation_dictionary[entry])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "# xml_files = [name for name in os.listdir('./Dataset/annotations')]\n",
    "# validation_dictionary = {}\n",
    "\n",
    "# for name in xml_files:\n",
    "#     # Parse the xml\n",
    "#     mytree = ET.parse('./Dataset/annotations/' + name)\n",
    "    \n",
    "#     # Get number from name\n",
    "#     order = ''.join(i for i in name if i.isdigit())\n",
    "    \n",
    "#     # Get sign type\n",
    "#     validation_dictionary[order] = mytree.getroot().find('object').find('name').text\n",
    "\n",
    "# sign_types = []\n",
    "# for entry in validation_dictionary:\n",
    "#     if validation_dictionary[entry] not in sign_types:\n",
    "#         sign_types.append(validation_dictionary[entry])\n",
    "# print(sign_types)\n",
    "# print(validation_dictionary)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
