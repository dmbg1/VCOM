{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Traffic Signs with OpenCV\n",
    "\n",
    "For this project we will be trying split the traffic sign dataset into 3 separate classes:\n",
    "- Stop signs\n",
    "- Red Circles\n",
    "- Blue rectangles/squares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import shutil\n",
    "import math\n",
    "from ImageList import ImageList\n",
    "from Image import Image\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list():\n",
    "    # Saves images into a list containing objects of class Image which contains traffic sign info \n",
    "    image_list = ImageList() \n",
    "    for root, _, files in os.walk('./dataset'):\n",
    "        for file in files:\n",
    "            split_file_path = os.path.join(root, file).split(os.sep)\n",
    "            filename = split_file_path[-1]\n",
    "            _type = split_file_path[-2][:-1]\n",
    "            # Prevent image duplicates\n",
    "            idx = image_list.contains_img(filename) \n",
    "            if idx >= 0:\n",
    "                image = image_list.get_image(idx)\n",
    "                image.add_type(_type)\n",
    "            else:\n",
    "                image = Image(filename, _type)\n",
    "                image_list.add_image(image)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(segmented_img, original_img, color):\n",
    "    segmented_img = smooth(segmented_img)\n",
    "    #_, segmented_img = cv.threshold(segmented_img,1,255,cv.THRESH_BINARY)\n",
    "    \n",
    "    if color == \"blue\":\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        segmented_img = cv.dilate(segmented_img, kernel, iterations=3)\n",
    "        segmented_img = cv.erode(segmented_img, kernel, iterations=3)\n",
    "        segmented_img = cv.Canny(segmented_img, 150, 200) \n",
    "        \n",
    "    final, prediction = search_contours(segmented_img, original_img.copy(), color)\n",
    "    \n",
    "    if type(prediction) != str: # Prediction is returned as a number if found contour has more than 8 edges\n",
    "        final, prediction = find_circles(segmented_img, original_img.copy(), int(prediction))\n",
    "        # if prediction == 'unrecognized':\n",
    "        #     final, prediction = find_circles_possibly(segmented_img, original_img, color)\n",
    "        \n",
    "    return final, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove image noise with gaussian blur (better at preserving edges)\n",
    "def smooth2(img):\n",
    "    return cv.GaussianBlur(img, (3,3), 0)\n",
    "\n",
    "def smooth(img):\n",
    "    return cv.bilateralFilter(img, 5, 75, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increases image brightness\n",
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    h, s, v = cv.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv.merge((h, s, v))\n",
    "    img = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Segments reds and blues of an image\n",
    "def segment(img, color):\n",
    "    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    if color == 'red':\n",
    "        # lower mask (0-10)\n",
    "        lower_red = np.array([0,90,50])\n",
    "        upper_red = np.array([10,255,255])\n",
    "        mask0 = cv.inRange(img_hsv, lower_red, upper_red)  \n",
    "\n",
    "        # upper mask (160-180)\n",
    "        lower_red = np.array([160,90,50])\n",
    "        upper_red = np.array([180,255,255])\n",
    "        mask1 = cv.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "        mask = mask0 | mask1\n",
    "    elif color == 'blue':\n",
    "        lower_blue = np.array([90,140,50])\n",
    "        upper_blue = np.array([130,255,255])\n",
    "        mask = cv.inRange(img_hsv, lower_blue, upper_blue) \n",
    "\n",
    "    segmented_img = cv.bitwise_and(img_hsv, img_hsv, mask = mask)\n",
    "    segmented_img = cv.cvtColor(segmented_img, cv.COLOR_BGR2GRAY)\n",
    "    return segmented_img    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contour with the largest area in a gray scale image\n",
    "def find_largest_contour(segmented_img, original_img):\n",
    "    contours, _ = cv.findContours(segmented_img,2,1)\n",
    "    cnt = contours\n",
    "    big_contour = []\n",
    "    max = 0\n",
    "    for i in cnt:\n",
    "        area = cv.contourArea(i)\n",
    "        if(area > max):\n",
    "            max = area\n",
    "            big_contour = i \n",
    "    if max > 1000 and len(big_contour) > 10 and len(big_contour) < 1200:\n",
    "        final = cv.drawContours(original_img, big_contour, -1, (0,255,0), 3)\n",
    "    else:\n",
    "        final = original_img\n",
    "\n",
    "    return final, big_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a blue square\n",
    "def search_contours(segmented_img, original_img, color):\n",
    "    if cv.countNonZero(segmented_img) == 0:\n",
    "        return original_img, 'unrecognised'\n",
    "    final, contour = find_largest_contour(segmented_img, original_img)\n",
    "    if len(contour) > 100:\n",
    "        peri = cv.arcLength(contour, True)\n",
    "        approx = cv.approxPolyDP(contour, 0.01 * peri, True)\n",
    "        if len(approx) > 8: # circle possibly\n",
    "            return final, cv.contourArea(contour)\n",
    "        return final, classify_sign(approx, color)\n",
    "\n",
    "    return final, 'unrecognised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sign(approx_cnt, color):\n",
    "    if color == 'blue':\n",
    "        if len(approx_cnt) == 4:\n",
    "            return 'blue_square'\n",
    "    elif color == 'red':\n",
    "        if len(approx_cnt) == 8:\n",
    "            return 'stop_sign'\n",
    "    return 'unrecognised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_circles(img, original_img, radius):\n",
    "    # Reduce white noise and enhance shapes\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img = cv.dilate(img, kernel, iterations = 3)\n",
    "    img = cv.erode(img, kernel, iterations = 3)\n",
    "    #Tolerance\n",
    "    tol = 5\n",
    "\n",
    "    circles = cv.HoughCircles(img, cv.HOUGH_GRADIENT, 1, radius * 2 - tol, param1=100, param2=45, minRadius=5, maxRadius=radius + tol)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0, :]:\n",
    "            center = (i[0], i[1])\n",
    "            r = i[2]\n",
    "            cv.circle(original_img, center, r, (0, 255, 0), 2)\n",
    "        return original_img, 'red_circle'\n",
    "    else:\n",
    "        return original_img, 'unrecognised'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Circles\n",
    "\n",
    "This is the section to detect red circles\n",
    "\n",
    "After processing the image to gray values holding as the white value the red features a contour finder is used to detect an ellipse correctly. It can also be used in the case of stop signs to obtain octagons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "shutil.rmtree('results/blue_squares')\n",
    "shutil.rmtree('results/red_circles')\n",
    "shutil.rmtree('results/stop_signs')\n",
    "shutil.rmtree('results/unknowns')\n",
    "os.mkdir('results/blue_squares')\n",
    "os.mkdir('results/red_circles')\n",
    "os.mkdir('results/stop_signs')\n",
    "os.mkdir('results/unknowns')\n",
    "\n",
    "dataset_path = 'dataset'\n",
    "results_path = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.854] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('dataset/red_circle/road161.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22372/1352505541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Keep an original copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Smooth image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Counters\n",
    "cnt_i_un = 0    # Counter for the amount of images unrecognised prior to more smoothing step if it is unrecognised\n",
    "cnt_un = 0      # Counter for the amount of images unrecognised after the more smoothing step\n",
    "\n",
    "#Image List\n",
    "img_list = get_image_list()\n",
    "\n",
    "for i in range(0, img_list.len()):\n",
    "    # Get img object from img_list\n",
    "    img_obj = img_list.get_image(i)\n",
    "\n",
    "    # Get path of that image -> {type(qualquer um serve)}/{filename}\n",
    "    img_path = img_obj.types[0] +'s' + os.sep + img_obj.filename\n",
    "\n",
    "    # Image in the dataset path\n",
    "    img_path_in_dataset = dataset_path + os.sep + img_path\n",
    "\n",
    "    # Read img\n",
    "    img = cv.imread(img_path_in_dataset)\n",
    "\n",
    "    # Keep an original copy\n",
    "    original = img.copy()\n",
    "\n",
    "    # Smooth image\n",
    "    img = smooth(img)\n",
    "\n",
    "    # Segment it by filtering the blue and red color for blue and red signs\n",
    "    img_blue, img_red = segment(img, 'blue'), segment(img, 'red')\n",
    "\n",
    "    # Variable to check if any sign is already detected for it not to be classified as unrecognised in that case\n",
    "    sign_detected = False\n",
    "\n",
    "    # Process blue segmented img\n",
    "    final, classification = process_image(img_blue.copy(), img.copy(), 'blue')\n",
    "\n",
    "    # Process first iteration result\n",
    "    if classification == 'blue_square':\n",
    "        img_obj.add_classification(classification)\n",
    "        cv.imwrite(os.path.join(results_path, classification + 's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "    elif classification == 'unrecognised': # if no sign detected do more smoothing \n",
    "        temp=smooth(smooth(smooth(img_blue)))\n",
    "        final, classification= process_image(temp,img.copy(),'blue')\n",
    "        if classification == 'blue_square':\n",
    "            img_obj.add_classification(classification)\n",
    "            cv.imwrite(os.path.join(results_path, classification + 's', img_obj.filename), final)\n",
    "            sign_detected =True\n",
    "\n",
    "    # Process red segmented img\n",
    "    final, classification = process_image(img_red.copy(), img.copy(), 'red')\n",
    "    \n",
    "    # Process first iteration result\n",
    "    if classification == 'stop_sign' or classification == 'red_circle':\n",
    "        img_obj.add_classification(classification)\n",
    "        cv.imwrite(os.path.join(\n",
    "            results_path, classification + 's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "    elif classification == 'unrecognised': # if no sign detected do more smoothing\n",
    "        if sign_detected == False:\n",
    "            cnt_i_un += 1\n",
    "        temp=smooth(img_red)\n",
    "        final, classification= process_image(temp,img.copy(),'red')\n",
    "        if classification == 'stop_sign' or classification=='red_circle':\n",
    "            img_obj.add_classification(classification)\n",
    "            cv.imwrite(os.path.join(results_path, classification + 's', img_obj.filename), final)\n",
    "            sign_detected = True\n",
    "\n",
    "    if sign_detected == False:\n",
    "        cnt_un += 1\n",
    "        print(cnt_un)\n",
    "        img_obj.add_classification(classification)\n",
    "        cv.imwrite(os.path.join(results_path, 'unknowns',img_obj.filename), final)\n",
    "\n",
    "logging.basicConfig(filename=\"info.log\", level=logging.INFO)\n",
    "logging.info(\"INITIAL UNKNOWNS BEFORE MORE SMOOTHING \" + str(cnt_i_un))\n",
    "logging.info(\"UNKNOWNS AFTER MORE SMOOTHING \" + str(cnt_un))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a perfect circle\n",
    "\n",
    "By using the HoughCircles function we are able to detect perfect circles in an image.\n",
    "\n",
    "There are some cases where it fits very well but if the sign is slanted no decent circle can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray_blurred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7767/4223733673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcircles\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_blurred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOUGH_GRADIENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ensure at least some circles were found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcircles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gray_blurred' is not defined"
     ]
    }
   ],
   "source": [
    "circles =  cv.HoughCircles(gray_blurred, cv.HOUGH_GRADIENT, 1.5, 100)\n",
    "output = img.copy()\n",
    "# ensure at least some circles were found\n",
    "print(circles)\n",
    "if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "    # loop over the (x, y) coordinates and radius of the circles\n",
    "    for (x, y, r) in circles:\n",
    "        # draw the circle in the output image, then draw a rectangle\n",
    "        # corresponding to the center of the circle\n",
    "        cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "        cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1) #center of circle\n",
    "        # show the output image\n",
    "    # cv.imshow(\"output\", np.hstack([img, output]))\n",
    "\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commented out cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we need to collect all of the xml files and the corresponding png files so we can parse them.\n",
    "Our dataset has 877 pictures of traffic sings with 4 distinctions: 'trafficlight', 'speedlimit', 'crosswalk' and 'stop'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml_files = [name for name in os.listdir('./Dataset/annotations')]\n",
    "# validation_dictionary = {}\n",
    "\n",
    "# for name in xml_files:\n",
    "#     # Parse the xml\n",
    "#     mytree = ET.parse('./Dataset/annotations/' + name)\n",
    "    \n",
    "#     # Get number from name\n",
    "#     order = ''.join(i for i in name if i.isdigit())\n",
    "    \n",
    "#     # Get sign type\n",
    "#     validation_dictionary[order] = mytree.getroot().find('object').find('name').text\n",
    "\n",
    "# sign_types = []\n",
    "# for entry in validation_dictionary:\n",
    "#     if validation_dictionary[entry] not in sign_types:\n",
    "#         sign_types.append(validation_dictionary[entry])\n",
    "# print(sign_types)\n",
    "# print(validation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
