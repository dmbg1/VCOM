{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Traffic Signs with OpenCV\n",
    "\n",
    "For this project we will be trying split the traffic sign dataset into 3 separate classes:\n",
    "- Stop signs\n",
    "- Red Circles\n",
    "- Blue rectangles/squares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import shutil\n",
    "from ImageList import ImageList\n",
    "from Image import Image\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results directories reset\n",
    "shutil.rmtree('results/blue_squares')\n",
    "shutil.rmtree('results/red_circles')\n",
    "shutil.rmtree('results/stop_signs')\n",
    "shutil.rmtree('results/unknowns')\n",
    "os.mkdir('results/blue_squares')\n",
    "os.mkdir('results/red_circles')\n",
    "os.mkdir('results/stop_signs')\n",
    "os.mkdir('results/unknowns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list():\n",
    "    # Saves images into a list containing objects of class Image which contains traffic sign info \n",
    "    image_list = ImageList() \n",
    "    for root, _, files in os.walk('./dataset'):\n",
    "        for file in files:\n",
    "            split_file_path = os.path.join(root, file).split(os.sep)\n",
    "            filename = split_file_path[-1]\n",
    "            _type = split_file_path[-2][:-1]\n",
    "            # Prevent image duplicates\n",
    "            idx = image_list.contains_img(filename) \n",
    "            if idx >= 0:\n",
    "                print(123)\n",
    "                image = image_list.get_image(idx)\n",
    "                image.add_type(_type)\n",
    "            else:\n",
    "                image = Image(filename, _type)\n",
    "                image_list.add_image(image)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(segmented_img, original_img, color):\n",
    "    segmented_img = smooth(segmented_img)\n",
    "    #_, segmented_img = cv.threshold(segmented_img,1,255,cv.THRESH_BINARY)\n",
    "    \n",
    "    if color == \"blue\":\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        segmented_img = cv.dilate(segmented_img, kernel, iterations=3)\n",
    "        segmented_img = cv.erode(segmented_img, kernel, iterations=3)\n",
    "        segmented_img = cv.Canny(segmented_img, 150, 200) \n",
    "        \n",
    "    final, prediction = search_contours(segmented_img, original_img.copy(), color)\n",
    "    \n",
    "    if type(prediction) != str: # Prediction is returned as a number if found contour has more than 8 edges\n",
    "        final, prediction = find_circles(segmented_img, original_img.copy(), int(prediction))\n",
    "        # if prediction == 'unrecognized':\n",
    "        #     final, prediction = find_circles_possibly(segmented_img, original_img, color)\n",
    "        \n",
    "    return final, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove image noise with gaussian blur (better at preserving edges)\n",
    "def smooth2(img):\n",
    "    return cv.GaussianBlur(img, (3,3), 0)\n",
    "\n",
    "def smooth(img):\n",
    "    return cv.bilateralFilter(img, 5, 75, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increases image brightness\n",
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    h, s, v = cv.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv.merge((h, s, v))\n",
    "    img = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Segments reds and blues of an image\n",
    "def segment(img, color):\n",
    "    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    if color == 'red':\n",
    "        # lower mask (0-10)\n",
    "        lower_red = np.array([0,90,50])\n",
    "        upper_red = np.array([10,255,255])\n",
    "        mask0 = cv.inRange(img_hsv, lower_red, upper_red)  \n",
    "\n",
    "        # upper mask (160-180)\n",
    "        lower_red = np.array([160,90,50])\n",
    "        upper_red = np.array([180,255,255])\n",
    "        mask1 = cv.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "        mask = mask0 | mask1\n",
    "    elif color == 'blue':\n",
    "        lower_blue = np.array([90,140,50])\n",
    "        upper_blue = np.array([130,255,255])\n",
    "        mask = cv.inRange(img_hsv, lower_blue, upper_blue) \n",
    "\n",
    "    segmented_img = cv.bitwise_and(img_hsv, img_hsv, mask = mask)\n",
    "    segmented_img = cv.cvtColor(segmented_img, cv.COLOR_BGR2GRAY)\n",
    "    return segmented_img    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contour with the largest area in a gray scale image\n",
    "def find_largest_contour(segmented_img, original_img):\n",
    "    contours, _ = cv.findContours(segmented_img,2,1)\n",
    "    cnt = contours\n",
    "    big_contour = []\n",
    "    max = 0\n",
    "    for i in cnt:\n",
    "        area = cv.contourArea(i)\n",
    "        if(area > max):\n",
    "            max = area\n",
    "            big_contour = i \n",
    "    if max > 1000 and len(big_contour) > 10 and len(big_contour) < 1200:\n",
    "        final = cv.drawContours(original_img, big_contour, -1, (0,255,0), 3)\n",
    "    else:\n",
    "        final = original_img\n",
    "\n",
    "    return final, big_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a blue square\n",
    "def search_contours(segmented_img, original_img, color):\n",
    "    if cv.countNonZero(segmented_img) == 0:\n",
    "        return original_img, 'unrecognised'\n",
    "    final, contour = find_largest_contour(segmented_img, original_img)\n",
    "    if len(contour) > 100:\n",
    "        peri = cv.arcLength(contour, True)\n",
    "        approx = cv.approxPolyDP(contour, 0.01 * peri, True)\n",
    "        if len(approx) > 8: # circle possibly\n",
    "            return final, cv.contourArea(contour)\n",
    "        return final, classify_sign(approx, color)\n",
    "\n",
    "    return final, 'unrecognised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sign(approx_cnt, color):\n",
    "    if color == 'blue':\n",
    "        if len(approx_cnt) == 4:\n",
    "            return 'blue_square'\n",
    "    elif color == 'red':\n",
    "        if len(approx_cnt) == 8:\n",
    "            return 'stop_sign'\n",
    "    return 'unrecognised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_circles(img, original_img, radius):\n",
    "    # Reduce white noise and enhance shapes\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img = cv.dilate(img, kernel, iterations = 3)\n",
    "    img = cv.erode(img, kernel, iterations = 3)\n",
    "    #Tolerance\n",
    "    tol = 5\n",
    "\n",
    "    circles = cv.HoughCircles(img, cv.HOUGH_GRADIENT, 1, radius * 2 - tol, param1=100, param2=45, minRadius=5, maxRadius=radius + tol)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0, :]:\n",
    "            center = (i[0], i[1])\n",
    "            r = i[2]\n",
    "            cv.circle(original_img, center, r, (0, 255, 0), 2)\n",
    "        return original_img, 'red_circle'\n",
    "    else:\n",
    "        return original_img, 'unrecognised'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Circles\n",
    "\n",
    "This is the section to detect red circles\n",
    "\n",
    "After processing the image to gray values holding as the white value the red features a contour finder is used to detect an ellipse correctly. It can also be used in the case of stop signs to obtain octagons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths and image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset'\n",
    "results_path = 'results'\n",
    "\n",
    "# Image List\n",
    "img_list = get_image_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Smoothing approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the amount of unrecognised traffic signs in the dataset images we tried to increase images smoothing until the results started getting worse. Thats why the \"amount\" of smoothing done in original images for blue segmented image processing is higher than the \"amount\" used in original images for red segmented images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO METER EXEMPLOS AQUI DO EFEITO DO SMOOTHING EM DIFERENTES IMAGENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Smoothing Amount Solutions Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different amount of bilateral (filter) smoothing applied in original images before segmenting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counters\n",
    "cnt_un1 = 0    # Counter for the amount of images unrecognised prior to using more smoothing if it is unrecognised\n",
    "cnt_un2 = 0      # Counter for the amount of images unrecognised after using more smoothing\n",
    "cnt_un3 = 0      # Counter for the amount of images unrecognised after using no smoothing\n",
    "\n",
    "# Accuracies before using lower amount of smoothing\n",
    "red_circles_accuracy1 = 0    # Red circles classification accuracy\n",
    "blue_squares_accuracy1 = 0    # Blue squares classification accuracy\n",
    "stop_signs_accuracy1 = 0    # Stop signs classification accuracy\n",
    "\n",
    "# Accuracies after using higher amount of smoothing\n",
    "red_circles_accuracy2 = 0    # Red circles classification accuracy\n",
    "blue_squares_accuracy2 = 0    # Blue squares classification accuracy\n",
    "stop_signs_accuracy2 = 0    # Stop signs classification accuracy\n",
    "\n",
    "# Accuracies after using no smoothing\n",
    "red_circles_accuracy3 = 0    # Red circles classification accuracy\n",
    "blue_squares_accuracy3 = 0    # Blue squares classification accuracy\n",
    "stop_signs_accuracy3 = 0    # Stop signs classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = 0\n",
    "while inp <= 0 or inp > 3:\n",
    "    inp = int(input('Select solution to be written to the results directory (1- Normal Smoothing; 2- High Smoothing; 3- No Smoothing): '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, img_list.len()):\n",
    "    # Get img object from img_list\n",
    "    img_obj = img_list.get_image(i)\n",
    "\n",
    "    # Get path of that image -> {type(qualquer um serve)}/{filename}\n",
    "    img_path = img_obj.types[0] + 's' + os.sep + img_obj.filename\n",
    "\n",
    "    # Image in the dataset path\n",
    "    img_path_in_dataset = dataset_path + os.sep + img_path\n",
    "\n",
    "    # Read img\n",
    "    img = cv.imread(img_path_in_dataset)\n",
    "\n",
    "    # Keep an original copy\n",
    "    original = img.copy()\n",
    "\n",
    "    # Smooth image\n",
    "    img = smooth(img)\n",
    "\n",
    "    # Segment it by filtering the blue and red color for blue and red signs\n",
    "    img_blue, img_red = segment(img, 'blue'), segment(img, 'red')\n",
    "\n",
    "    # Variable to check if any sign is already detected for it not to be classified as unrecognised in that case\n",
    "    sign_detected = False\n",
    "\n",
    "    # Process blue segmented img\n",
    "    final, classification = process_image(img_blue.copy(), img.copy(), 'blue')\n",
    "\n",
    "    if classification == 'blue_square':\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 1:\n",
    "            cv.imwrite(os.path.join(results_path, classification +\n",
    "                                    's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "\n",
    "    final, classification = process_image(img_red.copy(), img.copy(), 'red')\n",
    "    # Process first iteration result\n",
    "    if classification == 'stop_sign' or classification == 'red_circle':\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 1:\n",
    "            cv.imwrite(os.path.join(\n",
    "                results_path, classification + 's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "\n",
    "    if sign_detected == False:\n",
    "        cnt_un1 += 1\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 1:\n",
    "            cv.imwrite(os.path.join(\n",
    "                results_path, 'unknowns', img_obj.filename), final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, img_list.len()):\n",
    "    # Get img object from img_list\n",
    "    img_obj = img_list.get_image(i)\n",
    "\n",
    "    # Get path of that image -> {type(qualquer um serve)}/{filename}\n",
    "    img_path = img_obj.types[0] + 's' + os.sep + img_obj.filename\n",
    "\n",
    "    # Image in the dataset path\n",
    "    img_path_in_dataset = dataset_path + os.sep + img_path\n",
    "\n",
    "    # Read img\n",
    "    img = cv.imread(img_path_in_dataset)\n",
    "\n",
    "    # Keep an original copy\n",
    "    original = img.copy()\n",
    "\n",
    "    # Smooth image\n",
    "    img = smooth(img)\n",
    "\n",
    "    # Segment it by filtering the blue and red color for blue and red signs\n",
    "    img_blue, img_red = segment(img, 'blue'), segment(img, 'red')\n",
    "\n",
    "    # Variable to check if any sign is already detected for it not to be classified as unrecognised in that case\n",
    "    sign_detected = False\n",
    "\n",
    "    # Process blue segmented img\n",
    "    final, classification = process_image(img_blue.copy(), img.copy(), 'blue')\n",
    "\n",
    "    # Process first iteration result\n",
    "    if classification == 'blue_square':\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 2:\n",
    "            cv.imwrite(os.path.join(results_path, classification +\n",
    "                                    's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "    elif classification == 'unrecognised':  # if no sign detected do more smoothing\n",
    "        temp = smooth(smooth(smooth(img_blue)))\n",
    "        final, classification = process_image(temp, img.copy(), 'blue')\n",
    "        if classification == 'blue_square':\n",
    "            img_obj.add_classification(classification)\n",
    "            if inp == 2:\n",
    "                cv.imwrite(os.path.join(results_path, classification +\n",
    "                                        's', img_obj.filename), final)\n",
    "            sign_detected = True\n",
    "\n",
    "    # Process red segmented img\n",
    "    final, classification = process_image(img_red.copy(), img.copy(), 'red')\n",
    "\n",
    "    # Process first iteration result\n",
    "    if classification == 'stop_sign' or classification == 'red_circle':\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 2:\n",
    "            cv.imwrite(os.path.join(\n",
    "                results_path, classification + 's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "    elif classification == 'unrecognised':  # if no sign detected do more smoothing\n",
    "        temp = smooth(img_red)\n",
    "        final, classification = process_image(temp, img.copy(), 'red')\n",
    "        if classification == 'stop_sign' or classification == 'red_circle':\n",
    "            img_obj.add_classification(classification)\n",
    "            if inp == 2:\n",
    "                cv.imwrite(os.path.join(results_path, classification +\n",
    "                                        's', img_obj.filename), final)\n",
    "            sign_detected = True\n",
    "\n",
    "    if sign_detected == False:\n",
    "        cnt_un2 += 1\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 2:\n",
    "            cv.imwrite(os.path.join(\n",
    "                results_path, 'unknowns', img_obj.filename), final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/imgproc/src/hough.cpp:2260: error: (-211:One of the arguments' values is out of range) dp, min_dist and canny_threshold must be all positive numbers in function 'HoughCircles'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22372/2831896955.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Process blue segmented img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_blue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Process first iteration result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22372/3824405390.py\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(segmented_img, original_img, color)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Prediction is returned as a number if found contour has more than 8 edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_circles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# if prediction == 'unrecognized':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#     final, prediction = find_circles_possibly(segmented_img, original_img, color)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22372/731046244.py\u001b[0m in \u001b[0;36mfind_circles\u001b[0;34m(img, original_img, radius)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcircles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOUGH_GRADIENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminRadius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxRadius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcircles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/hough.cpp:2260: error: (-211:One of the arguments' values is out of range) dp, min_dist and canny_threshold must be all positive numbers in function 'HoughCircles'\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, img_list.len()):\n",
    "    # Get img object from img_list\n",
    "    img_obj = img_list.get_image(i)\n",
    "\n",
    "    # Get path of that image -> {type(qualquer um serve)}/{filename}\n",
    "    img_path = img_obj.types[0] + 's' + os.sep + img_obj.filename\n",
    "\n",
    "    # Image in the dataset path\n",
    "    img_path_in_dataset = dataset_path + os.sep + img_path\n",
    "\n",
    "    # Read img\n",
    "    img = cv.imread(img_path_in_dataset)\n",
    "\n",
    "    # Keep an original copy\n",
    "    original = img.copy()\n",
    "\n",
    "    # Segment it by filtering the blue and red color for blue and red signs\n",
    "    img_blue, img_red = segment(img, 'blue'), segment(img, 'red')\n",
    "\n",
    "    # Variable to check if any sign is already detected for it not to be classified as unrecognised in that case\n",
    "    sign_detected = False\n",
    "\n",
    "    # Process blue segmented img\n",
    "    final, classification = process_image(img_blue.copy(), img.copy(), 'blue')\n",
    "\n",
    "    # Process first iteration result\n",
    "    if classification == 'blue_square':\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 3:\n",
    "            cv.imwrite(os.path.join(results_path, classification +\n",
    "                                    's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "    elif classification == 'unrecognised':  # if no sign detected do more smoothing\n",
    "        temp = smooth(smooth(smooth(img_blue)))\n",
    "        final, classification = process_image(temp, img.copy(), 'blue')\n",
    "        if classification == 'blue_square':\n",
    "            img_obj.add_classification(classification)\n",
    "            if inp == 3:\n",
    "                cv.imwrite(os.path.join(results_path, classification +\n",
    "                                        's', img_obj.filename), final)\n",
    "            sign_detected = True\n",
    "\n",
    "    # Process red segmented img\n",
    "    final, classification = process_image(img_red.copy(), img.copy(), 'red')\n",
    "\n",
    "    # Process first iteration result\n",
    "    if classification == 'stop_sign' or classification == 'red_circle':\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 3:\n",
    "            cv.imwrite(os.path.join(\n",
    "                results_path, classification + 's', img_obj.filename), final)\n",
    "        sign_detected = True\n",
    "    elif classification == 'unrecognised':  # if no sign detected do more smoothing\n",
    "        temp = smooth(img_red)\n",
    "        final, classification = process_image(temp, img.copy(), 'red')\n",
    "        if classification == 'stop_sign' or classification == 'red_circle':\n",
    "            img_obj.add_classification(classification)\n",
    "            if inp == 3:\n",
    "                cv.imwrite(os.path.join(results_path, classification +\n",
    "                                        's', img_obj.filename), final)\n",
    "            sign_detected = True\n",
    "\n",
    "    if sign_detected == False:\n",
    "        cnt_un3 += 1\n",
    "        img_obj.add_classification(classification)\n",
    "        if inp == 3:\n",
    "            cv.imwrite(os.path.join(\n",
    "                results_path, 'unknowns', img_obj.filename), final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of unknowns (no traffic signs detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal amount of smoothing: 80\n",
      "Higher amount of smoothing: 58\n",
      "No smoothing: 10\n"
     ]
    }
   ],
   "source": [
    "print('Normal amount of smoothing: ' + str(cnt_un1))\n",
    "print('Higher amount of smoothing: ' + str(cnt_un2))\n",
    "print('No smoothing: ' + str(cnt_un3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a perfect circle\n",
    "\n",
    "By using the HoughCircles function we are able to detect perfect circles in an image.\n",
    "\n",
    "There are some cases where it fits very well but if the sign is slanted no decent circle can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray_blurred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22372/4223733673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcircles\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_blurred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOUGH_GRADIENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ensure at least some circles were found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcircles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gray_blurred' is not defined"
     ]
    }
   ],
   "source": [
    "circles =  cv.HoughCircles(gray_blurred, cv.HOUGH_GRADIENT, 1.5, 100)\n",
    "output = img.copy()\n",
    "# ensure at least some circles were found\n",
    "print(circles)\n",
    "if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "    # loop over the (x, y) coordinates and radius of the circles\n",
    "    for (x, y, r) in circles:\n",
    "        # draw the circle in the output image, then draw a rectangle\n",
    "        # corresponding to the center of the circle\n",
    "        cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "        cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1) #center of circle\n",
    "        # show the output image\n",
    "    # cv.imshow(\"output\", np.hstack([img, output]))\n",
    "\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commented out cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we need to collect all of the xml files and the corresponding png files so we can parse them.\n",
    "Our dataset has 877 pictures of traffic sings with 4 distinctions: 'trafficlight', 'speedlimit', 'crosswalk' and 'stop'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml_files = [name for name in os.listdir('./Dataset/annotations')]\n",
    "# validation_dictionary = {}\n",
    "\n",
    "# for name in xml_files:\n",
    "#     # Parse the xml\n",
    "#     mytree = ET.parse('./Dataset/annotations/' + name)\n",
    "    \n",
    "#     # Get number from name\n",
    "#     order = ''.join(i for i in name if i.isdigit())\n",
    "    \n",
    "#     # Get sign type\n",
    "#     validation_dictionary[order] = mytree.getroot().find('object').find('name').text\n",
    "\n",
    "# sign_types = []\n",
    "# for entry in validation_dictionary:\n",
    "#     if validation_dictionary[entry] not in sign_types:\n",
    "#         sign_types.append(validation_dictionary[entry])\n",
    "# print(sign_types)\n",
    "# print(validation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
